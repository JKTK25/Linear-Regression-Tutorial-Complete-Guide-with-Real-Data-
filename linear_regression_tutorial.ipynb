{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Tutorial\n",
    "## Complete Guide with Real Data - California Housing Prices\n",
    "\n",
    "This notebook will teach you linear regression from basics to practical implementation using real-world housing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Linear Regression\n",
    "\n",
    "**Linear Regression** is a statistical method that models the relationship between:\n",
    "- **Independent variable(s)** (features) - X\n",
    "- **Dependent variable** (target) - y\n",
    "\n",
    "The model assumes a linear relationship: $y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n + \\epsilon$\n",
    "\n",
    "Where:\n",
    "- $\\beta_0$: Intercept\n",
    "- $\\beta_1, \\beta_2, ...$: Coefficients\n",
    "- $\\epsilon$: Error term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California Housing dataset\n",
    "california = fetch_california_housing()\n",
    "df = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "df['MedHouseVal'] = california.target * 100000  # Convert to actual dollar amounts\n",
    "\n",
    "print(\"üìä Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Features: {list(df.columns)}\")\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"üìà Dataset Description:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nüîç Missing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['MedHouseVal'], bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "plt.xlabel('Median House Value ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Median House Values')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df['MedHouseVal'], color='lightcoral')\n",
    "plt.title('Box Plot of Median House Values')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, fmt='.2f')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "- **MedInc** has the strongest positive correlation with house values (0.69)\n",
    "- **Latitude** and **AveRooms** also show significant correlations\n",
    "- **AveRooms** and **AveBedrms** are highly correlated (0.85) - potential multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine relationships with target variable\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "features = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup']\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    axes[i].scatter(df[feature], df['MedHouseVal'], alpha=0.5, s=10)\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('MedHouseVal')\n",
    "    axes[i].set_title(f'{feature} vs House Value')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Simple Linear Regression\n",
    "Let's start with one feature: Median Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for simple linear regression\n",
    "X_simple = df[['MedInc']]\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_simple, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "simple_model = LinearRegression()\n",
    "simple_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_simple = simple_model.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "mse_simple = mean_squared_error(y_test, y_pred_simple)\n",
    "rmse_simple = np.sqrt(mse_simple)\n",
    "mae_simple = mean_absolute_error(y_test, y_pred_simple)\n",
    "r2_simple = r2_score(y_test, y_pred_simple)\n",
    "\n",
    "print(\"üîç Simple Linear Regression Results:\")\n",
    "print(f\"Intercept (Œ≤‚ÇÄ): ${simple_model.intercept_:,.2f}\")\n",
    "print(f\"Coefficient (Œ≤‚ÇÅ): ${simple_model.coef_[0]:,.2f}\")\n",
    "print(f\"Mean Squared Error: ${mse_simple:,.2f}\")\n",
    "print(f\"Root Mean Squared Error: ${rmse_simple:,.2f}\")\n",
    "print(f\"Mean Absolute Error: ${mae_simple:,.2f}\")\n",
    "print(f\"R¬≤ Score: {r2_simple:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "- **Intercept**: When median income is 0, predicted house value is $45,177 (theoretical baseline)\n",
    "- **Coefficient**: For each unit increase in median income ($10,000), house value increases by $42,927\n",
    "- **R¬≤**: 47% of the variance in house values is explained by median income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the simple linear regression\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "# Training data with regression line\n",
    "plt.scatter(X_train, y_train, alpha=0.5, s=20, label='Training Data', color='blue')\n",
    "plt.plot(X_train, simple_model.predict(X_train), color='red', \n",
    "         linewidth=2, label='Regression Line')\n",
    "plt.xlabel('Median Income (tens of thousands)')\n",
    "plt.ylabel('Median House Value ($)')\n",
    "plt.title('Simple Linear Regression - Training Data')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Test data with predictions\n",
    "plt.scatter(X_test, y_test, alpha=0.5, s=20, label='Actual Test Data', color='green')\n",
    "plt.scatter(X_test, y_pred_simple, alpha=0.7, s=20, color='red', \n",
    "           label='Predicted Values', marker='x')\n",
    "plt.xlabel('Median Income (tens of thousands)')\n",
    "plt.ylabel('Median House Value ($)')\n",
    "plt.title('Predictions vs Actual - Test Data')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multiple Linear Regression\n",
    "Now let's use all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for multiple regression\n",
    "X_multiple = df.drop('MedHouseVal', axis=1)\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "# Split the data\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "    X_multiple, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Features used:\", list(X_multiple.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train multiple regression model\n",
    "multiple_model = LinearRegression()\n",
    "multiple_model.fit(X_train_m, y_train_m)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_multiple = multiple_model.predict(X_test_m)\n",
    "\n",
    "# Model evaluation\n",
    "mse_multiple = mean_squared_error(y_test_m, y_pred_multiple)\n",
    "rmse_multiple = np.sqrt(mse_multiple)\n",
    "mae_multiple = mean_absolute_error(y_test_m, y_pred_multiple)\n",
    "r2_multiple = r2_score(y_test_m, y_pred_multiple)\n",
    "\n",
    "print(\"üîç Multiple Linear Regression Results:\")\n",
    "print(f\"Intercept (Œ≤‚ÇÄ): ${multiple_model.intercept_:,.2f}\")\n",
    "print(\"\\nüìä Coefficients:\")\n",
    "for feature, coef in zip(X_multiple.columns, multiple_model.coef_):\n",
    "    print(f\"  {feature:12}: ${coef:10,.2f}\")\n",
    "    \n",
    "print(f\"\\nüìà Performance Metrics:\")\n",
    "print(f\"Mean Squared Error: ${mse_multiple:,.2f}\")\n",
    "print(f\"Root Mean Squared Error: ${rmse_multiple:,.2f}\")\n",
    "print(f\"Mean Absolute Error: ${mae_multiple:,.2f}\")\n",
    "print(f\"R¬≤ Score: {r2_multiple:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Coefficients:\n",
    "- **MedInc**: Strong positive effect - each unit increase adds $40,747 to house value\n",
    "- **HouseAge**: Positive effect - older houses are generally more valuable\n",
    "- **AveRooms**: Positive effect - more rooms increase value\n",
    "- **AveBedrms**: Negative effect - might indicate larger households in less expensive areas\n",
    "- **Population**: Slight negative effect - more densely populated areas might be less expensive\n",
    "- **AveOccup**: Negative effect - higher occupancy might indicate lower income areas\n",
    "- **Latitude**: Strong effect - geographic location significantly impacts price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Simple (MedInc only)', 'Multiple (All Features)'],\n",
    "    'R¬≤ Score': [r2_simple, r2_multiple],\n",
    "    'RMSE': [rmse_simple, rmse_multiple],\n",
    "    'MAE': [mae_simple, mae_multiple]\n",
    "})\n",
    "\n",
    "print(\"üìä Model Comparison:\")\n",
    "print(comparison.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_test_m, y_pred_multiple, alpha=0.5, color='purple')\n",
    "plt.plot([y_test_m.min(), y_test_m.max()], [y_test_m.min(), y_test_m.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Values ($)')\n",
    "plt.ylabel('Predicted Values ($)')\n",
    "plt.title('Multiple Regression: Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "residuals = y_test_m - y_pred_multiple\n",
    "plt.scatter(y_pred_multiple, residuals, alpha=0.5, color='orange')\n",
    "plt.axhline(y=0, color='r', linestyle='--', label='Zero Residual')\n",
    "plt.xlabel('Predicted Values ($)')\n",
    "plt.ylabel('Residuals ($)')\n",
    "plt.title('Residual Plot')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(residuals, bins=50, edgecolor='black', alpha=0.7, color='lightgreen')\n",
    "plt.axvline(residuals.mean(), color='red', linestyle='--', label=f'Mean: ${residuals.mean():.2f}')\n",
    "plt.xlabel('Residuals ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Diagnostics and Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check linear regression assumptions\n",
    "print(\"üîç LINEAR REGRESSION ASSUMPTIONS CHECK:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Linearity assumption\n",
    "print(\"\\n1. üìà LINEARITY: Check residual plot above\")\n",
    "print(\"   - Residuals should be randomly scattered around zero\")\n",
    "print(\"   - No clear patterns in residual plot\")\n",
    "\n",
    "# 2. Normality of residuals\n",
    "print(\"\\n2. üìä NORMALITY OF RESIDUALS:\")\n",
    "print(f\"   - Mean of residuals: ${residuals.mean():.2f} (should be near 0)\")\n",
    "\n",
    "# Handle large datasets for Shapiro-Wilk test\n",
    "if len(residuals) > 5000:\n",
    "    residuals_sample = residuals.sample(5000, random_state=42)\n",
    "    stat, p_value = stats.shapiro(residuals_sample)\n",
    "else:\n",
    "    stat, p_value = stats.shapiro(residuals)\n",
    "    \n",
    "print(f\"   - Shapiro-Wilk test p-value: {p_value:.4f}\")\n",
    "print(\"     (p > 0.05 suggests normality)\")\n",
    "\n",
    "# 3. Homoscedasticity\n",
    "print(\"\\n3. ‚öñÔ∏è HOMOSCEDASTICITY:\")\n",
    "print(\"   - Check residual plot: spread should be constant across predicted values\")\n",
    "print(\"   - Our plot shows some heteroscedasticity (fan shape)\")\n",
    "\n",
    "# 4. Independence of errors\n",
    "print(\"\\n4. üîÑ INDEPENDENCE OF ERRORS:\")\n",
    "dw_stat = durbin_watson(residuals)\n",
    "print(f\"   - Durbin-Watson statistic: {dw_stat:.4f}\")\n",
    "print(\"     (2.0 = no autocorrelation, <1.0 or >3.0 may be problematic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q plot for normality check\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot for Normality Check')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(residuals, bins=50, density=True, alpha=0.7, edgecolor='black', color='lightblue')\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = stats.norm.pdf(x, residuals.mean(), residuals.std())\n",
    "plt.plot(x, p, 'r', linewidth=2, label='Normal Distribution')\n",
    "plt.title('Residual Distribution vs Normal')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance based on coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_multiple.columns,\n",
    "    'Coefficient': multiple_model.coef_,\n",
    "    'Abs_Coefficient': np.abs(multiple_model.coef_)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"üìä Feature Importance (by coefficient magnitude):\")\n",
    "print(feature_importance.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if x > 0 else 'red' for x in feature_importance['Coefficient']]\n",
    "bars = plt.barh(feature_importance['Feature'], feature_importance['Coefficient'], color=colors)\n",
    "plt.xlabel('Coefficient Value ($)')\n",
    "plt.title('Feature Impact on House Prices')\n",
    "plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width, bar.get_y() + bar.get_height()/2, \n",
    "             f'${width:,.0f}', \n",
    "             ha='left' if width > 0 else 'right', \n",
    "             va='center', fontweight='bold')\n",
    "\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Making Predictions - Practical Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Predict house price for a new observation\n",
    "example_house = {\n",
    "    'MedInc': [4.5],        # $45,000 median income\n",
    "    'HouseAge': [25],       # 25 years old\n",
    "    'AveRooms': [5.2],      # Average 5.2 rooms\n",
    "    'AveBedrms': [1.1],     # Average 1.1 bedrooms\n",
    "    'Population': [1200],   # 1200 people in block group\n",
    "    'AveOccup': [2.8],      # Average 2.8 people per household\n",
    "    'Latitude': [34.05],    # Southern California\n",
    "    'Longitude': [-118.24]  # Los Angeles area\n",
    "}\n",
    "\n",
    "example_df = pd.DataFrame(example_house)\n",
    "predicted_price = multiple_model.predict(example_df)[0]\n",
    "\n",
    "print(\"üè† EXAMPLE PREDICTION:\")\n",
    "print(\"House Characteristics:\")\n",
    "for feature, value in example_house.items():\n",
    "    print(f\"  {feature}: {value[0]}\")\n",
    "print(f\"\\nüí∞ Predicted Median House Value: ${predicted_price:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity analysis: How does changing income affect prediction?\n",
    "incomes = np.linspace(1, 10, 20)  # From $10,000 to $100,000\n",
    "sensitivity_df = example_df.copy()\n",
    "\n",
    "predicted_prices = []\n",
    "for income in incomes:\n",
    "    sensitivity_df['MedInc'] = income\n",
    "    price = multiple_model.predict(sensitivity_df)[0]\n",
    "    predicted_prices.append(price)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(incomes * 10000, predicted_prices, 'b-', linewidth=2, marker='o')\n",
    "plt.xlabel('Median Income ($)')\n",
    "plt.ylabel('Predicted House Value ($)')\n",
    "plt.title('Sensitivity Analysis: Income vs House Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ KEY TAKEAWAYS:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. üìö LINEAR REGRESSION BASICS:\")\n",
    "print(\"   - Models relationship between features and target variable\")\n",
    "print(\"   - Assumes linear relationship: y = Œ≤‚ÇÄ + Œ≤‚ÇÅX‚ÇÅ + Œ≤‚ÇÇX‚ÇÇ + ...\")\n",
    "print(\"   - Coefficients represent feature importance and direction\")\n",
    "\n",
    "print(\"\\n2. üìä MODEL PERFORMANCE:\")\n",
    "print(f\"   - Simple model (1 feature): R¬≤ = {r2_simple:.3f}\")\n",
    "print(f\"   - Multiple model (8 features): R¬≤ = {r2_multiple:.3f}\")\n",
    "print(\"   - Adding relevant features improves predictive power\")\n",
    "\n",
    "print(\"\\n3. üè† CALIFORNIA HOUSING INSIGHTS:\")\n",
    "print(\"   - Median income is the strongest predictor of house values\")\n",
    "print(\"   - Geographic location (latitude) significantly impacts prices\")\n",
    "print(\"   - House age has a positive but relatively small effect\")\n",
    "\n",
    "print(\"\\n4. ‚ö†Ô∏è MODEL LIMITATIONS:\")\n",
    "print(\"   - Residuals show heteroscedasticity (uneven variance)\")\n",
    "print(\"   - Some non-linear relationships may exist\")\n",
    "print(\"   - Could benefit from feature engineering or polynomial terms\")\n",
    "\n",
    "print(\"\\n5. üöÄ NEXT STEPS TO IMPROVE:\")\n",
    "print(\"   - Try polynomial features for non-linear relationships\")\n",
    "print(\"   - Consider regularization (Ridge/Lasso regression)\")\n",
    "print(\"   - Feature engineering (e.g., room-to-bedroom ratio)\")\n",
    "print(\"   - Address heteroscedasticity with transformations\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ Congratulations! You've completed the Linear Regression tutorial!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and key metrics for future reference\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(multiple_model, 'california_housing_model.pkl')\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "\n",
    "# Save model performance\n",
    "performance = pd.DataFrame({\n",
    "    'Metric': ['R¬≤', 'RMSE', 'MAE'],\n",
    "    'Simple_Regression': [r2_simple, rmse_simple, mae_simple],\n",
    "    'Multiple_Regression': [r2_multiple, rmse_multiple, mae_multiple]\n",
    "})\n",
    "performance.to_csv('model_performance.csv', index=False)\n",
    "\n",
    "print(\"üíæ Files saved successfully!\")\n",
    "print(\"- california_housing_model.pkl (trained model)\")\n",
    "print(\"- feature_importance.csv (feature coefficients)\")\n",
    "print(\"- model_performance.csv (model metrics)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
